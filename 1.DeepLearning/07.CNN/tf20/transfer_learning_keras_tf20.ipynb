{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "# boilerplate code\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import cv2 #python -m pip install opencv-python\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_cifar10_data(img_rows, img_cols):\n",
    "    # Load cifar10 training and test sets\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "    # Resize training images\n",
    "    X_train = np.array([cv2.resize(img, (img_rows, img_cols)) for img in X_train[:, :, :, :]])\n",
    "    X_test = np.array([cv2.resize(img, (img_rows, img_cols)) for img in X_test[:, :, :, :]])\n",
    "\n",
    "    X_train = X_train.astype('float16') / 255.0\n",
    "    X_test = X_test.astype('float16') / 255.0\n",
    "\n",
    "    # Transform targets to keras compatible format\n",
    "    Y_train = to_categorical(Y_train, num_classes)\n",
    "    Y_test = to_categorical(Y_test, num_classes)\n",
    "\n",
    "    print(\"X_train: {0}\".format(X_train.shape))\n",
    "    print(\"Y_train: {0}\".format(Y_train.shape))\n",
    "    print(\"X_test: {0}\".format(X_test.shape))\n",
    "    print(\"Y_test: {0}\".format(Y_test.shape))\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (50000, 224, 224, 3)\n",
      "Y_train: (50000, 10)\n",
      "X_test: (10000, 224, 224, 3)\n",
      "Y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_cifar10_data(224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "def build_model(nb_classes):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=[224, 224, 3])\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # and a logistic layer\n",
    "\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 111, 111, 32) 864         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_376 (Bat (None, 111, 111, 32) 96          conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 111, 111, 32) 0           batch_normalization_v1_376[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 109, 109, 32) 9216        activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_377 (Bat (None, 109, 109, 32) 96          conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 109, 109, 32) 0           batch_normalization_v1_377[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 109, 109, 64) 18432       activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_378 (Bat (None, 109, 109, 64) 192         conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 109, 109, 64) 0           batch_normalization_v1_378[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 54, 54, 64)   0           activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_379 (Bat (None, 54, 54, 80)   240         conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 54, 54, 80)   0           batch_normalization_v1_379[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 52, 52, 192)  138240      activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_380 (Bat (None, 52, 52, 192)  576         conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 52, 52, 192)  0           batch_normalization_v1_380[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 25, 25, 192)  0           activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_384 (Bat (None, 25, 25, 64)   192         conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_384[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 25, 25, 96)   55296       activation_384[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_382 (Bat (None, 25, 25, 48)   144         conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_385 (Bat (None, 25, 25, 96)   288         conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 25, 25, 48)   0           batch_normalization_v1_382[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_385[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_36 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 25, 25, 64)   76800       activation_382[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 25, 25, 96)   82944       activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_381 (Bat (None, 25, 25, 64)   192         conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_383 (Bat (None, 25, 25, 64)   192         conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_386 (Bat (None, 25, 25, 96)   288         conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_387 (Bat (None, 25, 25, 32)   96          conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_381[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_383[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_386[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 25, 25, 32)   0           batch_normalization_v1_387[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_381[0][0]             \n",
      "                                                                 activation_383[0][0]             \n",
      "                                                                 activation_386[0][0]             \n",
      "                                                                 activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_391 (Bat (None, 25, 25, 64)   192         conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_391[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, 25, 25, 96)   55296       activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_389 (Bat (None, 25, 25, 48)   144         conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_392 (Bat (None, 25, 25, 96)   288         conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 25, 25, 48)   0           batch_normalization_v1_389[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_392[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_37 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, 25, 25, 64)   76800       activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, 25, 25, 96)   82944       activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_37[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_388 (Bat (None, 25, 25, 64)   192         conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_390 (Bat (None, 25, 25, 64)   192         conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_393 (Bat (None, 25, 25, 96)   288         conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_394 (Bat (None, 25, 25, 64)   192         conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_388[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_390[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_393[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_394[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_388[0][0]             \n",
      "                                                                 activation_390[0][0]             \n",
      "                                                                 activation_393[0][0]             \n",
      "                                                                 activation_394[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_398 (Bat (None, 25, 25, 64)   192         conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_398[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, 25, 25, 96)   55296       activation_398[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_396 (Bat (None, 25, 25, 48)   144         conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_399 (Bat (None, 25, 25, 96)   288         conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 25, 25, 48)   0           batch_normalization_v1_396[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_399[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_38 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, 25, 25, 64)   76800       activation_396[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, 25, 25, 96)   82944       activation_399[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_395 (Bat (None, 25, 25, 64)   192         conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_397 (Bat (None, 25, 25, 64)   192         conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_400 (Bat (None, 25, 25, 96)   288         conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_401 (Bat (None, 25, 25, 64)   192         conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_395[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_397[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_400[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_401 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_401[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_395[0][0]             \n",
      "                                                                 activation_397[0][0]             \n",
      "                                                                 activation_400[0][0]             \n",
      "                                                                 activation_401[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_403 (Bat (None, 25, 25, 64)   192         conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_403 (Activation)     (None, 25, 25, 64)   0           batch_normalization_v1_403[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, 25, 25, 96)   55296       activation_403[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_404 (Bat (None, 25, 25, 96)   288         conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_404 (Activation)     (None, 25, 25, 96)   0           batch_normalization_v1_404[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 12, 12, 96)   82944       activation_404[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_402 (Bat (None, 12, 12, 384)  1152        conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_405 (Bat (None, 12, 12, 96)   288         conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_402 (Activation)     (None, 12, 12, 384)  0           batch_normalization_v1_402[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, 12, 12, 96)   0           batch_normalization_v1_405[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_402[0][0]             \n",
      "                                                                 activation_405[0][0]             \n",
      "                                                                 max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_410 (Bat (None, 12, 12, 128)  384         conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_410 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_410[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, 12, 12, 128)  114688      activation_410[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_411 (Bat (None, 12, 12, 128)  384         conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_411 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_411[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, 12, 12, 128)  114688      activation_411[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_407 (Bat (None, 12, 12, 128)  384         conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_412 (Bat (None, 12, 12, 128)  384         conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_407[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_412 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_412[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 12, 12, 128)  114688      activation_407[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, 12, 12, 128)  114688      activation_412[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_408 (Bat (None, 12, 12, 128)  384         conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_413 (Bat (None, 12, 12, 128)  384         conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_408[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_413 (Activation)     (None, 12, 12, 128)  0           batch_normalization_v1_413[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_39 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 12, 12, 192)  172032      activation_408[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, 12, 12, 192)  172032      activation_413[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_39[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_406 (Bat (None, 12, 12, 192)  576         conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_409 (Bat (None, 12, 12, 192)  576         conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_414 (Bat (None, 12, 12, 192)  576         conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_415 (Bat (None, 12, 12, 192)  576         conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_406[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_409 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_409[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_414 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_414[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_415 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_415[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_406[0][0]             \n",
      "                                                                 activation_409[0][0]             \n",
      "                                                                 activation_414[0][0]             \n",
      "                                                                 activation_415[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_420 (Bat (None, 12, 12, 160)  480         conv2d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_420 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_420[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, 12, 12, 160)  179200      activation_420[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_421 (Bat (None, 12, 12, 160)  480         conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_421 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_421[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, 12, 12, 160)  179200      activation_421[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_417 (Bat (None, 12, 12, 160)  480         conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_422 (Bat (None, 12, 12, 160)  480         conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_417 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_417[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_422 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_422[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, 12, 12, 160)  179200      activation_417[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_423 (Conv2D)             (None, 12, 12, 160)  179200      activation_422[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_418 (Bat (None, 12, 12, 160)  480         conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_423 (Bat (None, 12, 12, 160)  480         conv2d_423[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_418 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_418[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_423 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_423[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_40 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, 12, 12, 192)  215040      activation_418[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_424 (Conv2D)             (None, 12, 12, 192)  215040      activation_423[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_425 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_40[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_416 (Bat (None, 12, 12, 192)  576         conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_419 (Bat (None, 12, 12, 192)  576         conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_424 (Bat (None, 12, 12, 192)  576         conv2d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_425 (Bat (None, 12, 12, 192)  576         conv2d_425[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_416 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_416[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_419 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_419[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_424 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_424[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_425 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_425[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_416[0][0]             \n",
      "                                                                 activation_419[0][0]             \n",
      "                                                                 activation_424[0][0]             \n",
      "                                                                 activation_425[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_430 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_430 (Bat (None, 12, 12, 160)  480         conv2d_430[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_430 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_430[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_431 (Conv2D)             (None, 12, 12, 160)  179200      activation_430[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_431 (Bat (None, 12, 12, 160)  480         conv2d_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_431 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_431[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_427 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_432 (Conv2D)             (None, 12, 12, 160)  179200      activation_431[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_427 (Bat (None, 12, 12, 160)  480         conv2d_427[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_432 (Bat (None, 12, 12, 160)  480         conv2d_432[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_427 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_427[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_432[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_428 (Conv2D)             (None, 12, 12, 160)  179200      activation_427[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_433 (Conv2D)             (None, 12, 12, 160)  179200      activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_428 (Bat (None, 12, 12, 160)  480         conv2d_428[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_433 (Bat (None, 12, 12, 160)  480         conv2d_433[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_428 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_428[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, 12, 12, 160)  0           batch_normalization_v1_433[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_41 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_426 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_429 (Conv2D)             (None, 12, 12, 192)  215040      activation_428[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_434 (Conv2D)             (None, 12, 12, 192)  215040      activation_433[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_435 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_41[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_426 (Bat (None, 12, 12, 192)  576         conv2d_426[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_429 (Bat (None, 12, 12, 192)  576         conv2d_429[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_434 (Bat (None, 12, 12, 192)  576         conv2d_434[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_435 (Bat (None, 12, 12, 192)  576         conv2d_435[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_426 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_426[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_429 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_429[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_434 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_434[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_435 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_435[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_426[0][0]             \n",
      "                                                                 activation_429[0][0]             \n",
      "                                                                 activation_434[0][0]             \n",
      "                                                                 activation_435[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_440 (Bat (None, 12, 12, 192)  576         conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_440 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_440[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, 12, 12, 192)  258048      activation_440[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_441 (Bat (None, 12, 12, 192)  576         conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_441 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_441[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, 12, 12, 192)  258048      activation_441[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_437 (Bat (None, 12, 12, 192)  576         conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_442 (Bat (None, 12, 12, 192)  576         conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_437 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_437[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_442 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_442[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, 12, 12, 192)  258048      activation_437[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, 12, 12, 192)  258048      activation_442[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_438 (Bat (None, 12, 12, 192)  576         conv2d_438[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_443 (Bat (None, 12, 12, 192)  576         conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_438 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_438[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_443 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_443[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_42 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_436 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, 12, 12, 192)  258048      activation_438[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, 12, 12, 192)  258048      activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_436 (Bat (None, 12, 12, 192)  576         conv2d_436[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_439 (Bat (None, 12, 12, 192)  576         conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_444 (Bat (None, 12, 12, 192)  576         conv2d_444[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_445 (Bat (None, 12, 12, 192)  576         conv2d_445[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_436 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_436[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_439 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_439[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_444 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_444[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_445 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_445[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_436[0][0]             \n",
      "                                                                 activation_439[0][0]             \n",
      "                                                                 activation_444[0][0]             \n",
      "                                                                 activation_445[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_448 (Bat (None, 12, 12, 192)  576         conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_448 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_448[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, 12, 12, 192)  258048      activation_448[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_449 (Bat (None, 12, 12, 192)  576         conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_449 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_449[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_446 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, 12, 12, 192)  258048      activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_446 (Bat (None, 12, 12, 192)  576         conv2d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_450 (Bat (None, 12, 12, 192)  576         conv2d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_446 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_446[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_450 (Activation)     (None, 12, 12, 192)  0           batch_normalization_v1_450[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_447 (Conv2D)             (None, 5, 5, 320)    552960      activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, 5, 5, 192)    331776      activation_450[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_447 (Bat (None, 5, 5, 320)    960         conv2d_447[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_451 (Bat (None, 5, 5, 192)    576         conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_447 (Activation)     (None, 5, 5, 320)    0           batch_normalization_v1_447[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_451 (Activation)     (None, 5, 5, 192)    0           batch_normalization_v1_451[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_447[0][0]             \n",
      "                                                                 activation_451[0][0]             \n",
      "                                                                 max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_456 (Bat (None, 5, 5, 448)    1344        conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_456 (Activation)     (None, 5, 5, 448)    0           batch_normalization_v1_456[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 5, 5, 384)    1548288     activation_456[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_453 (Bat (None, 5, 5, 384)    1152        conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_457 (Bat (None, 5, 5, 384)    1152        conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_453 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_453[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_457 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_457[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 5, 5, 384)    442368      activation_453[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 5, 5, 384)    442368      activation_453[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 5, 5, 384)    442368      activation_457[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 5, 5, 384)    442368      activation_457[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_43 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_454 (Bat (None, 5, 5, 384)    1152        conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_455 (Bat (None, 5, 5, 384)    1152        conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_458 (Bat (None, 5, 5, 384)    1152        conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_459 (Bat (None, 5, 5, 384)    1152        conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_43[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_452 (Bat (None, 5, 5, 320)    960         conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_454 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_454[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_455 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_455[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_458 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_458[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_459 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_459[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_460 (Bat (None, 5, 5, 192)    576         conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_452 (Activation)     (None, 5, 5, 320)    0           batch_normalization_v1_452[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_454[0][0]             \n",
      "                                                                 activation_455[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5, 5, 768)    0           activation_458[0][0]             \n",
      "                                                                 activation_459[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_460 (Activation)     (None, 5, 5, 192)    0           batch_normalization_v1_460[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_452[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 activation_460[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_465 (Bat (None, 5, 5, 448)    1344        conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_465 (Activation)     (None, 5, 5, 448)    0           batch_normalization_v1_465[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 5, 5, 384)    1548288     activation_465[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_462 (Bat (None, 5, 5, 384)    1152        conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_466 (Bat (None, 5, 5, 384)    1152        conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_462 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_462[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_466 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_466[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 5, 5, 384)    442368      activation_462[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 5, 5, 384)    442368      activation_462[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 5, 5, 384)    442368      activation_466[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 5, 5, 384)    442368      activation_466[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_44 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_463 (Bat (None, 5, 5, 384)    1152        conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_464 (Bat (None, 5, 5, 384)    1152        conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_467 (Bat (None, 5, 5, 384)    1152        conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_468 (Bat (None, 5, 5, 384)    1152        conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_461 (Bat (None, 5, 5, 320)    960         conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_463 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_463[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_464 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_464[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_467 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_467[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_468 (Activation)     (None, 5, 5, 384)    0           batch_normalization_v1_468[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_469 (Bat (None, 5, 5, 192)    576         conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_461 (Activation)     (None, 5, 5, 320)    0           batch_normalization_v1_461[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_463[0][0]             \n",
      "                                                                 activation_464[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 5, 5, 768)    0           activation_467[0][0]             \n",
      "                                                                 activation_468[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_469 (Activation)     (None, 5, 5, 192)    0           batch_normalization_v1_469[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_461[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 activation_469[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           10250       dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,911,210\n",
      "Trainable params: 2,108,426\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 1/35\n",
      "50000/50000 [==============================] - 115s 2ms/sample - loss: 0.9365 - accuracy: 0.6937 - val_loss: 0.9326 - val_accuracy: 0.7324\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 2/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.6586 - accuracy: 0.7757 - val_loss: 1.0182 - val_accuracy: 0.7327\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 3/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.6099 - accuracy: 0.7902 - val_loss: 1.1192 - val_accuracy: 0.7195\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 4/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.5761 - accuracy: 0.8040 - val_loss: 0.9620 - val_accuracy: 0.7474\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 5/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.5545 - accuracy: 0.8111 - val_loss: 1.0152 - val_accuracy: 0.7397\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 6/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.5337 - accuracy: 0.8182 - val_loss: 1.0424 - val_accuracy: 0.7447\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.01.\n",
      "Epoch 7/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.5222 - accuracy: 0.8196 - val_loss: 1.1333 - val_accuracy: 0.7223\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0096.\n",
      "Epoch 8/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.5006 - accuracy: 0.8293 - val_loss: 1.0818 - val_accuracy: 0.7346\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0096.\n",
      "Epoch 9/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.4874 - accuracy: 0.8336 - val_loss: 1.0310 - val_accuracy: 0.7427\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0096.\n",
      "Epoch 10/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.4707 - accuracy: 0.8405 - val_loss: 1.0148 - val_accuracy: 0.7501\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0096.\n",
      "Epoch 11/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.4588 - accuracy: 0.8425 - val_loss: 1.0767 - val_accuracy: 0.7430\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0096.\n",
      "Epoch 12/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.4411 - accuracy: 0.8517 - val_loss: 1.0721 - val_accuracy: 0.7423\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0096.\n",
      "Epoch 13/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.4283 - accuracy: 0.8555 - val_loss: 1.1018 - val_accuracy: 0.7419\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0096.\n",
      "Epoch 14/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.4141 - accuracy: 0.8601 - val_loss: 1.0046 - val_accuracy: 0.7532\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0096.\n",
      "Epoch 15/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.4020 - accuracy: 0.8648 - val_loss: 1.0224 - val_accuracy: 0.7485\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.009216.\n",
      "Epoch 16/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.3867 - accuracy: 0.8708 - val_loss: 1.0656 - val_accuracy: 0.7488\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.009216.\n",
      "Epoch 17/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.3676 - accuracy: 0.8771 - val_loss: 1.0650 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.009216.\n",
      "Epoch 18/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.3517 - accuracy: 0.8824 - val_loss: 1.2003 - val_accuracy: 0.7337\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.009216.\n",
      "Epoch 19/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.3402 - accuracy: 0.8879 - val_loss: 1.1812 - val_accuracy: 0.7355\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.009216.\n",
      "Epoch 20/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.3271 - accuracy: 0.8945 - val_loss: 1.0818 - val_accuracy: 0.7536\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.009216.\n",
      "Epoch 21/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.3106 - accuracy: 0.9006 - val_loss: 1.2280 - val_accuracy: 0.7350\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.009216.\n",
      "Epoch 22/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2962 - accuracy: 0.9065 - val_loss: 1.1183 - val_accuracy: 0.7487\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.009216.\n",
      "Epoch 23/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.2793 - accuracy: 0.9129 - val_loss: 1.2345 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.008847359999999999.\n",
      "Epoch 24/35\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 0.2650 - accuracy: 0.9179 - val_loss: 1.1454 - val_accuracy: 0.7495\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.008847359999999999.\n",
      "Epoch 25/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2507 - accuracy: 0.9243 - val_loss: 1.2144 - val_accuracy: 0.7392\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.008847359999999999.\n",
      "Epoch 26/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.2382 - accuracy: 0.9298 - val_loss: 1.2761 - val_accuracy: 0.7394\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.008847359999999999.\n",
      "Epoch 27/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.2269 - accuracy: 0.9341 - val_loss: 1.2846 - val_accuracy: 0.7307\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.008847359999999999.\n",
      "Epoch 28/35\n",
      "50000/50000 [==============================] - 113s 2ms/sample - loss: 0.2146 - accuracy: 0.9380 - val_loss: 1.2653 - val_accuracy: 0.7390\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.008847359999999999.\n",
      "Epoch 29/35\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 0.2032 - accuracy: 0.9437 - val_loss: 1.2419 - val_accuracy: 0.7390\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.008847359999999999.\n",
      "Epoch 30/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.1940 - accuracy: 0.9466 - val_loss: 1.2860 - val_accuracy: 0.7413\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.008847359999999999.\n",
      "Epoch 31/35\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.1843 - accuracy: 0.9500 - val_loss: 1.1967 - val_accuracy: 0.7477\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.008493465599999998.\n",
      "Epoch 32/35\n",
      "50000/50000 [==============================] - 113s 2ms/sample - loss: 0.1703 - accuracy: 0.9560 - val_loss: 1.2392 - val_accuracy: 0.7448\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.008493465599999998.\n",
      "Epoch 33/35\n",
      "50000/50000 [==============================] - 113s 2ms/sample - loss: 0.1612 - accuracy: 0.9598 - val_loss: 1.3992 - val_accuracy: 0.7313\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.008493465599999998.\n",
      "Epoch 34/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1536 - accuracy: 0.9621 - val_loss: 1.2836 - val_accuracy: 0.7453\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.008493465599999998.\n",
      "Epoch 35/35\n",
      "50000/50000 [==============================] - 110s 2ms/sample - loss: 0.1460 - accuracy: 0.9653 - val_loss: 1.3378 - val_accuracy: 0.7389\n"
     ]
    }
   ],
   "source": [
    "initial_lrate = 0.01\n",
    "\n",
    "def decay(epoch, steps=100):\n",
    "    drop = 0.96\n",
    "    epochs_drop = 8\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
    "\n",
    "sgd = SGD(lr=initial_lrate, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=sgd,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "epochs = 35\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs, batch_size=256, callbacks=[lr_sc]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
